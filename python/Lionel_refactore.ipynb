{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pylab nbagg\n",
    "#%matplotlib inline\n",
    "#%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.io as io\n",
    "import h5py\n",
    "\n",
    "import phate\n",
    "from sklearn.cluster import KMeans\n",
    "import os\n",
    "\n",
    "from functions.load_data import  go_avalanches\n",
    "from functions.plot import  plot_figure_2D, plot_figure_2D_patient"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DATASET EXTRACTION"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#remove suject 11,15,20\n",
    "subjects = ['43','39','38','35','34','29','26','21','20','19','18','17','15','13','9','8','6','5']\n",
    "Nsubs=44\n",
    "subject='1'\n",
    "nregions=90"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#original sampling at 1024 Hz. Data downsampled to 256 Hz.\n",
    "f_MEG=1024\n",
    "Tlen=160*f_MEG\n",
    "\n",
    "nedges=int(nregions**2/2-nregions/2)\n",
    "\n",
    "iTriup= np.triu_indices(nregions,k=1)  #nedges=len(iTriup[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Edge to Nodes\n",
    "dic={}\n",
    "for e in range(nedges):\n",
    "    dic['%d'%e]=[iTriup[0][e],iTriup[1][e]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path_data = os.path.dirname(os.path.realpath(__file__))+'/data/'\n",
    "f = h5py.File(path_data+'serie_Melbourne.mat','r')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "struArray = f['D']\n",
    "data={}\n",
    "for i in range(Nsubs):\n",
    "    data['%d'%i]=np.swapaxes(f[struArray[i, 0]][:nregions,:],0,1)\n",
    "Avalanches_human=go_avalanches(data[subject],thre=3,direc=0,binsize=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "avalanches_bin = []\n",
    "avalanches_sum = []\n",
    "for subject in subjects:\n",
    "    Avalanches_human=go_avalanches(data[subject],thre=3,direc=0,binsize=1)\n",
    "    Mag=np.mean(Avalanches_human['Zbin'],axis=1)\n",
    "    out=[[] for i in range(len(Avalanches_human['ranges']))]\n",
    "    out_sum=[[] for i in range(len(Avalanches_human['ranges']))]\n",
    "    for kk1 in range(len(Avalanches_human['ranges'])):\n",
    "        begin = Avalanches_human['ranges'][kk1][0]\n",
    "        end = Avalanches_human['ranges'][kk1][1]\n",
    "        sum_kk = np.sum(Avalanches_human['Zbin'][begin:end,:],0)\n",
    "        out_sum[kk1] = sum_kk\n",
    "        out[kk1]= np.zeros(nregions)\n",
    "        out[kk1][np.where(sum_kk>=1)]=1\n",
    "\n",
    "    avalanches_bin.append(np.concatenate([out],axis=1))\n",
    "    avalanches_sum.append(np.concatenate([out_sum],axis=1))\n",
    "    out = np.concatenate([out],axis=1)\n",
    "    out_sum = np.concatenate([out_sum],axis=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # save one subject\n",
    "# io.savemat('subject_'+str(subject)+'.mat',{'source_reconstruction_MEG':data,\n",
    "#                                            'avalanches_binarize':out,\n",
    "#                                            'avalanches_sum':out_sum})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Shuffle data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## example shuffle data\n",
    "shuffle_index= np.arange(out.shape[0])\n",
    "np.random.shuffle(shuffle_index)\n",
    "out_shuffle = np.squeeze(out[shuffle_index])\n",
    "phate_operator = phate.PHATE(n_components=3, n_jobs=-2, decay=1.0,  n_pca=10, gamma=1, knn=5, knn_dist='cosine'   )\n",
    "Y_phate = phate_operator.fit_transform(out)\n",
    "Y_phate_shuffle = phate_operator.fit_transform(out_shuffle)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualisation of the output shuffle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "fig = plt.figure()\n",
    "plt.scatter(Y_phate[:,0],Y_phate[:,1])\n",
    "fig = plt.figure()\n",
    "plt.scatter(Y_phate_shuffle[:,0],Y_phate_shuffle[:,1])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# all data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "knn_dist = 'cosine'\n",
    "mds_dist = 'cosine'\n",
    "knn_dist_name=knn_dist\n",
    "for n_components in range(2,6):\n",
    "    for n_pca in [5]:\n",
    "        for gamma in [-1.0,0.0,1.0]:\n",
    "            if not os.path.exists(\"../projection_data/all_subject_Y_phate_knn_dist_\"+knn_dist_name\n",
    "                                  +\"_mds_dist_\"+mds_dist+\"_nb_comp_\"+str(n_components)+\"_nb_pca_\"+str(n_pca)\n",
    "                                  +\"_gamma_\"+str(gamma)+\".npy\"):\n",
    "                phate_operator = phate.PHATE(n_components=n_components, n_jobs=-2, decay=1.0,  n_pca=n_pca,\n",
    "                                             gamma=gamma, knn=5, knn_dist=knn_dist, mds_dist=mds_dist )\n",
    "                Y_phate = phate_operator.fit_transform(avalanches_bin)\n",
    "                np.save(\"all_subject_Y_phate_knn_dist_\"+knn_dist_name+\"_mds_dist_\"+mds_dist\n",
    "                        +\"_nb_comp_\"+str(n_components)+\"_nb_pca_\"+str(n_pca)+\"_gamma_\"+str(gamma)+\".npy\",Y_phate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "for knn_dist_name,mds_dist,n_components,n_pca,gamma,nb_cluster in [('cosine','cosine',2,5,1.0,10),\n",
    "                                                                   ('cosine','cosine',2,5,0.0,10),\n",
    "                                                                   ('cosine','cosine',2,5,-1.0,10)]:\n",
    "    file = \"../projection_data/all_subject_Y_phate_knn_dist_\"+knn_dist_name+\"_mds_dist_\"+mds_dist\\\n",
    "           +\"_nb_comp_\"+str(n_components)+\"_nb_pca_\"+str(n_pca)+\"_gamma_\"+str(gamma)\n",
    "    data = np.load(file+'.npy')\n",
    "    plot_figure_2D(data,file,KMeans(n_clusters=nb_cluster, random_state=123).fit_predict(data))\n",
    "\n",
    "knn_dist = 'cosine'\n",
    "mds_dist = 'cosine'\n",
    "knn_dist_name=knn_dist\n",
    "nb_cluster= 5\n",
    "for n_components in range(2,6):\n",
    "    for n_pca in [5]:\n",
    "        for gamma in [-1.0,0.0,1.0]:\n",
    "            file = \"all_subject_Y_phate_knn_dist_\"+knn_dist_name+\"_mds_dist_\"+mds_dist\\\n",
    "                   +\"_nb_comp_\"+str(n_components)+\"_nb_pca_\"+str(n_pca)+\"_gamma_\"+str(gamma)+\".npy\"\n",
    "            data=np.load(file)\n",
    "            plot_figure_2D(data,file,KMeans(n_clusters=nb_cluster, random_state=123).fit_predict(data))\n",
    "            plot_figure_2D_patient(data,file,avalanches_sum)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cluster Result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cluster = KMeans(n_clusters=nb_cluster, random_state=123).fit_predict(data)\n",
    "file = \"../projection_data/all_subject_Y_phate_knn_dist_cosine_mds_dist_cosine_nb_comp_2_nb_pca_5_gamma_-1.0.npy\"\n",
    "save = True\n",
    "plot = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cluster_patient_data = []\n",
    "begin = 0\n",
    "for avalanche in avalanches_bin:\n",
    "    end = begin + len(avalanche)\n",
    "    cluster_patient_data.append(cluster[begin:end])\n",
    "    begin = end\n",
    "cluster_patient = np.empty((len(avalanches_bin),nb_cluster))\n",
    "transition = np.empty((len(subjects),nb_cluster,nb_cluster))\n",
    "histograms_patient = np.empty((len(subjects),nb_cluster))\n",
    "for index_patient, cluster_k in enumerate(cluster_patient_data):\n",
    "    hist = np.histogram(cluster_k,bins=nb_cluster,range=(0,12))\n",
    "    histograms_patient[index_patient,:]=hist[0]\n",
    "    next_step = cluster_k[1:]\n",
    "    step = cluster_k[:-1]\n",
    "    for i in range(nb_cluster):\n",
    "        data = next_step[np.where(step==i)]\n",
    "        percentage_trans = np.bincount(data)/len(data)\n",
    "        if len(percentage_trans) < nb_cluster:\n",
    "            percentage_trans = np.concatenate([percentage_trans,np.zeros(nb_cluster-percentage_trans.shape[0])])\n",
    "        transition[index_patient,i,:] = percentage_trans\n",
    "if plot:\n",
    "    for index_patient, cluster_k in enumerate(cluster_patient_data):\n",
    "        fig, axs = plt.subplots(1,2)\n",
    "        axs[0].hist(cluster_k,bins=nb_cluster,range=(0,12))\n",
    "        im = axs[1].imshow(transition[index_patient],vmin = 0.0)\n",
    "        fig.colorbar(im)\n",
    "if save :\n",
    "    data = np.load(file)\n",
    "    io.savemat('../projection_data/cluster_18_patients.mat',\n",
    "               {'avalanches_binarize':np.concatenate(avalanches_bin),\n",
    "                'cluster_index':KMeans(n_clusters=nb_cluster, random_state=123).fit_predict(data),\n",
    "                'PHATE_position':data,\n",
    "                'transition_matrix':transition,\n",
    "                'histogram':histograms_patient})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}